{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ef1261b-c7b6-4115-9762-11e1b6ff5e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchmetrics in c:\\users\\budik\\appdata\\roaming\\python\\python311\\site-packages (1.7.4)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\budik\\appdata\\roaming\\python\\python311\\site-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\programdata\\anaconda3\\envs\\ai_cv\\lib\\site-packages (from torchmetrics) (24.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\programdata\\anaconda3\\envs\\ai_cv\\lib\\site-packages (from torchmetrics) (2.5.1+cu121)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\budik\\appdata\\roaming\\python\\python311\\site-packages (from torchmetrics) (0.14.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\ai_cv\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (78.1.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\budik\\appdata\\roaming\\python\\python311\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.14.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\ai_cv\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\envs\\ai_cv\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\ai_cv\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\envs\\ai_cv\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\budik\\appdata\\roaming\\python\\python311\\site-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\envs\\ai_cv\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\ai_cv\\lib\\site-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a1da29-355b-4009-84fe-7eb3c27bcbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23984f4f-d99f-4e36-a1e3-7fbf8293b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount(\"/content/drive\")\n",
    "\n",
    "# TEST_IMG_PATH = \"/content/drive/MyDrive/AI/Cityscape/images_prepped_test-20230811T065241Z-001\"\n",
    "# TEST_MASK_PATH = \"/content/drive/MyDrive/AI/Cityscape/annotations_prepped_test-20230811T065240Z-001\"\n",
    "\n",
    "# EDA_DS_PATH = \"/content/drive/MyDrive/AI/Advance CV - Project 3/Dataset\"\n",
    "# EDA_TRAIN_LABELS = os.path.join(EDA_DS_PATH, \"train_labels.csv\")\n",
    "# EDA_TRAIN_FILES = os.path.join(EDA_DS_PATH, \"train_files.csv\")\n",
    "# EDA_VAL_FILES = os.path.join(EDA_DS_PATH, \"val_files.csv\")\n",
    "\n",
    "# MODEL_PATH = \"/content/drive/MyDrive/AI/Advance CV - Project 3/models/UNet\"\n",
    "# MODEL_PATH_FCN8S = \"/content/drive/MyDrive/AI/Advance CV - Project 3/models/FCN8s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8bc236f-1605-4583-93c1-3d5a8fe71b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMG_PATH = \"./dataset/bootcamp/test/images\"\n",
    "TEST_MASK_PATH = \"./dataset/bootcamp/test/annotations\"\n",
    "\n",
    "EDA_DS_PATH = \"./dataset/bootcamp/train\"\n",
    "EDA_TRAIN_LABELS = os.path.join(EDA_DS_PATH, \"train_labels.csv\")\n",
    "EDA_TRAIN_FILES = os.path.join(EDA_DS_PATH, \"train_files.csv\")\n",
    "EDA_VAL_FILES = os.path.join(EDA_DS_PATH, \"val_files.csv\")\n",
    "\n",
    "MODEL_PATH = \"./models/UNet\"\n",
    "MODEL_PATH_FCN8S = \"./models/FCN8s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f506424e-15af-405b-bdf1-745723ff8eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Files: 101, Image: 101, Mask: 101\n",
      "    class         label\n",
      "0       0           sky\n",
      "1       1      building\n",
      "2       2          pole\n",
      "3       3          road\n",
      "4       4      sidewalk\n",
      "5       5    vegetation\n",
      "6       6  traffic sign\n",
      "7       7         fence\n",
      "8       8       vehicle\n",
      "9       9        person\n",
      "10     10         rider\n",
      "11     11          void\n"
     ]
    }
   ],
   "source": [
    "# use validation images for inference test\n",
    "labels_df = pd.read_csv(EDA_TRAIN_LABELS)\n",
    "\n",
    "image_files = os.listdir(TEST_IMG_PATH)\n",
    "mask_files = os.listdir(TEST_MASK_PATH)\n",
    "\n",
    "test_files = [x for x in image_files if x in mask_files]\n",
    "\n",
    "print(f\"Test Files: {len(test_files)}, Image: {len(image_files)}, Mask: {len(mask_files)}\")\n",
    "\n",
    "print(labels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b0418-ca34-4ab4-ae34-61e4f66b5c9f",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17fb4fed-5224-419c-8e32-2fcd06dcd90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import CityScapes\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_datasets = CityScapes(TEST_IMG_PATH, TEST_MASK_PATH, test_files)\n",
    "test_dataloader = DataLoader(test_datasets, batch_size=32, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f79358-8ae5-44e1-b2a9-1d4b68b11e0c",
   "metadata": {},
   "source": [
    "## Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40883610-2c03-43da-aa49-6226a2cad5e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (1966150826.py, line 9)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mend_event = torch.cuda.Event(enable_timing=True\u001b[39m\n                                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "    \n",
    "def unnormalize(tensor, mean, std):\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor\n",
    "\n",
    "def visualize_results(images, preds, masks, labels_df):\n",
    "    \"\"\"Visualize batch results\"\"\"\n",
    "    n_classes = len(labels_df)\n",
    "    legend_colors = [plt.cm.nipy_spectral(i / (n_classes - 1)) for i in range(n_classes)]\n",
    "    legend_labels = [f\"{labels_df['label'][i]}\" for i in range(n_classes)]\n",
    "    patches = [mpatches.Patch(color=legend_colors[i], label=legend_labels[i]) for i in range(n_classes)]\n",
    "    \n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std  = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    fig, axs = plt.subplots(3, 4, figsize=(20, 18))\n",
    "    for i in range(4):  # Show first 4 samples\n",
    "        # print(f\"{i}: Min: {images[i].min()}, Max: {images[i].max()}\")\n",
    "        \n",
    "        img = unnormalize(images[i].clone(), mean, std)\n",
    "        # Input image\n",
    "        axs[0,i].imshow(img.permute(1,2,0).cpu().numpy())\n",
    "        axs[0,i].set_title(f\"Input {i}\")\n",
    "        axs[0,i].axis('off')\n",
    "        \n",
    "        # Prediction\n",
    "        axs[1,i].imshow(preds[i].cpu().numpy(), \n",
    "                       cmap='nipy_spectral', vmin=0, vmax=n_classes-1)\n",
    "        axs[1,i].set_title(f\"Pred {i}\")\n",
    "        axs[1,i].axis('off')\n",
    "        \n",
    "        # Ground Truth\n",
    "        axs[2,i].imshow(masks[i].cpu().numpy(), \n",
    "                       cmap='nipy_spectral', vmin=0, vmax=n_classes-1)\n",
    "        axs[2,i].set_title(f\"GT {i}\")\n",
    "        axs[2,i].axis('off')\n",
    "    fig.legend(handles=patches, loc='lower center', ncol=n_classes, fontsize='large', frameon=False)\n",
    "    fig.subplots_adjust(bottom=0.15)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11705477-fade-4dc0-a082-3d3992f14f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.segmentation import dice_score\n",
    "from torchmetrics import JaccardIndex\n",
    "import time\n",
    "\n",
    "# def inferences(model, test_dataloader, labels_df):\n",
    "#     total_time = 0\n",
    "#     num_classes = len(labels_df)\n",
    "#     all_dice_scores = []\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model.to(device).eval()  # âœ… Model to device + eval mode\n",
    "\n",
    "#     # Warm-up (avoid CUDA init overhead)\n",
    "#     with torch.no_grad():\n",
    "#         warmup = next(iter(test_dataloader))\n",
    "#         _ = inference(warmup[0].to(device), model)\n",
    "\n",
    "#     # Initialize metrics\n",
    "#     jaccard = JaccardIndex(task='multiclass', num_classes=num_classes).to(device)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch, (images, masks) in enumerate(test_dataloader, 1):\n",
    "#             # Move data to device (correctly)\n",
    "#             images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "#             # Time inference with synchronization\n",
    "#             start = torch.cuda.Event(enable_timing=True)\n",
    "#             end = torch.cuda.Event(enable_timing=True)\n",
    "#             start.record()\n",
    "#             logits, probs, preds, _ = inference(images, model)\n",
    "#             end.record()\n",
    "#             torch.cuda.synchronize()\n",
    "#             inf_time = start.elapsed_time(end) / 1000  # Seconds\n",
    "            \n",
    "#             # Compute metrics\n",
    "#             dice = dice_score(preds, masks, num_classes=num_classes, average='macro', input_format='index')\n",
    "#             all_dice_scores.extend(dice.cpu().tolist())\n",
    "#             jaccard.update(preds, masks)\n",
    "#             total_time += inf_time\n",
    "\n",
    "#     # Final metrics\n",
    "#     avg_dice = torch.mean(torch.tensor(all_dice_scores))\n",
    "#     mIoU = jaccard.compute()\n",
    "\n",
    "#     out_iou_per_class = mIoU.cpu().numpy()\n",
    "    \n",
    "#     print(f\"\\nDataset Metrics:\")\n",
    "#     print(f\"- Per-class IoU: {out_iou_per_class}\")\n",
    "#     print(f\"- Mean IoU (mIoU): {mIoU.item():.4f}\")\n",
    "#     print(f\"- Average Dice: {avg_dice:.4f}\")\n",
    "#     print(f\"- Total Inference Time: {total_time:.4f}s\")\n",
    "    \n",
    "#     return (\n",
    "#         out_iou_per_class,  # Per-class IoU\n",
    "#         mIoU.item(),                      # Mean IoU\n",
    "#         avg_dice.item(),                  # Avg Dice\n",
    "#         total_time                        # Total time\n",
    "#     )\n",
    "\n",
    "\n",
    "def inference(batch_tensor, model, device='cuda'):\n",
    "    \"\"\"Proper batch inference function that handles all caases\"\"\"\n",
    "    \n",
    "    #GPU-optimized inference with accurate timing.\n",
    "    # Initialize CUDA events\n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Ensure correct input dimensions\n",
    "        if batch_tensor.dim() == 3:  # Single image (C,H,W)\n",
    "            batch_tensor = batch_tensor.unsqueeze(0)  # Add batch dim\n",
    "        elif batch_tensor.dim() != 4:  # Not standard 4D input\n",
    "            raise ValueError(f\"Expected 3D or 4D input, got {batch_tensor.dim()}D\")\n",
    "        \n",
    "        batch_tensor = batch_tensor.to(device)\n",
    "        \n",
    "        # Synchronize and record time\n",
    "        torch.cuda.synchronize()  # Wait for pending GPU ops\n",
    "        start_event.record()\n",
    "        logits = model(batch_tensor)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        end_event.record()\n",
    "        torch.cuda.synchronize()  # Ensure all work is done\n",
    "        inf_time = start_event.elapsed_time(end_event) / 1000  # Convert ms to seconds\n",
    "\n",
    "    return logits, probs, preds, inf_time\n",
    "    \n",
    "def inferences(model, test_dataloader, labels_df):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    - model: model\n",
    "    - test_dataloader: dataloader\n",
    "    \"\"\"\n",
    "    \n",
    "    total_time = 0\n",
    "    num_classes = len(labels_df)\n",
    "    all_dice_scores = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Initialize metrics\n",
    "    jaccard = JaccardIndex(\n",
    "        task='multiclass',\n",
    "        num_classes=num_classes,\n",
    "        ignore_index=None,\n",
    "        average='none'  # Track per-class IoU\n",
    "    ).to(device)\n",
    "    batch = 0\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, masks in test_dataloader:\n",
    "            batch = batch + 1\n",
    "            print(f\"Batch Size: {len(images)}, batch: {batch} of {len(test_dataloader)}\")\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            # Verify shapes\n",
    "            if batch == 1:\n",
    "                print(\"Input shape:\", images.shape)  # Should be [B,C,H,W]\n",
    "                print(\"Mask shape:\", masks.shape)   # Should be [B,H,W]\n",
    "            \n",
    "            # Run inference\n",
    "            logits, probs, preds, inf_time = inference(images, model)\n",
    "            print(f\"Inf time:{inf_time:.4f}\")\n",
    "            preds = preds.to(device).long()\n",
    "            masks = masks.to(device).long()\n",
    "            \n",
    "            # Update Dice (per batch)\n",
    "            # input_format='index' if masks.shape is [B, H, W]\n",
    "            # if mask [B, C, H, W] input format='probabilities'\n",
    "            dice = dice_score(preds, masks, num_classes=num_classes, average='micro', input_format='index')\n",
    "            all_dice_scores.extend(dice.cpu().tolist())\n",
    "            \n",
    "            # Update IoU (accumulate across batches)\n",
    "            jaccard.update(preds, masks)\n",
    "            \n",
    "            total_time += inf_time\n",
    "            print()\n",
    "            \n",
    "    # Compute final metrics\n",
    "    iou_per_class = jaccard.compute()  # IoU per class [num_classes]\n",
    "    mIoU = torch.mean(iou_per_class)   # Mean IoU (scalar)\n",
    "    # print(\"Raw Dice scores:\", all_dice_scores)\n",
    "    avg_dice = sum(all_dice_scores) / len(all_dice_scores)\n",
    "\n",
    "    out_iou_per_class = iou_per_class.cpu().numpy().round(4)\n",
    "    out_mean_iou = mIoU.item()\n",
    "    print(f\"\\nDataset Metrics:\")\n",
    "    print(f\"- Per-class IoU: {out_iou_per_class}\")\n",
    "    print(f\"- Mean IoU (mIoU): {out_mean_iou:.4f}\")\n",
    "    print(f\"- Average Dice: {avg_dice:.4f}\")\n",
    "    print(f\"- Total Inference Time: {total_time:.4f}s\")\n",
    "    \n",
    "    return out_iou_per_class, out_mean_iou, avg_dice, total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24149caa-3c87-4c69-9c03-17d55a2e81da",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46d976cd-73ea-481d-999a-197cb40ab102",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e16306cf-5224-46f4-bf9e-40c8abb0793e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 32, batch: 1 of 4\n",
      "Input shape: torch.Size([32, 3, 256, 256])\n",
      "Mask shape: torch.Size([32, 256, 256])\n",
      "Inf time:1.1070\n",
      "\n",
      "Batch Size: 32, batch: 2 of 4\n",
      "Inf time:0.8233\n",
      "\n",
      "Batch Size: 32, batch: 3 of 4\n",
      "Inf time:1.3307\n",
      "\n",
      "Batch Size: 5, batch: 4 of 4\n",
      "Inf time:0.1054\n",
      "\n",
      "\n",
      "Dataset Metrics:\n",
      "- Per-class IoU: [0.9371 0.8088 0.1542 0.9452 0.8363 0.8372 0.3528 0.     0.577  0.3909\n",
      " 0.     0.2537]\n",
      "- Mean IoU (mIoU): 0.5078\n",
      "- Average Dice: 0.8801\n",
      "- Total Inference Time: 3.3665s\n"
     ]
    }
   ],
   "source": [
    "from architecture import UNET\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "model = UNET(in_channels=3, out_channels=len(labels_df))\n",
    "state_dict = torch.load(os.path.join(MODEL_PATH, 'best_model_dice.pth'), weights_only=True)\n",
    "missing, unexpected = model.load_state_dict(state_dict)\n",
    "# print(\"Missing keys:\", missing)\n",
    "\n",
    "iou_per_class, mean_iou, avg_dice, total_time = inferences(model,test_dataloader,labels_df)\n",
    "metrics.append({\n",
    "    \"Architecture\": \"UNet\",\n",
    "    \"Loss Function\": \"Dice Loss\",\n",
    "    \"IoU_per_class\": iou_per_class,\n",
    "    \"Mean_IoU\": mean_iou,\n",
    "    \"Avg_Dice\": avg_dice,\n",
    "    \"Total_Time\": total_time\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42091432-0353-4fcd-bbdb-e21f1934c198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 32, batch: 1 of 4\n",
      "Input shape: torch.Size([32, 3, 256, 256])\n",
      "Mask shape: torch.Size([32, 256, 256])\n",
      "Inf time:0.8496\n",
      "\n",
      "Batch Size: 32, batch: 2 of 4\n",
      "Inf time:0.8495\n",
      "\n",
      "Batch Size: 32, batch: 3 of 4\n",
      "Inf time:1.3685\n",
      "\n",
      "Batch Size: 5, batch: 4 of 4\n",
      "Inf time:0.1116\n",
      "\n",
      "\n",
      "Dataset Metrics:\n",
      "- Per-class IoU: [0.9343 0.8452 0.0763 0.9686 0.8672 0.8838 0.3131 0.5895 0.6708 0.3183\n",
      " 0.5661 0.2247]\n",
      "- Mean IoU (mIoU): 0.6048\n",
      "- Average Dice: 0.9132\n",
      "- Total Inference Time: 3.1792s\n"
     ]
    }
   ],
   "source": [
    "model = UNET(in_channels=3, out_channels=len(labels_df))\n",
    "state_dict = torch.load(os.path.join(MODEL_PATH, 'best_model_cross.pth'), weights_only=True)\n",
    "missing, unexpected = model.load_state_dict(state_dict)\n",
    "# print(\"Missing keys:\", missing)\n",
    "\n",
    "iou_per_class, mean_iou, avg_dice, total_time = inferences(model,test_dataloader,labels_df)\n",
    "metrics.append({\n",
    "    \"Architecture\": \"UNet\",\n",
    "    \"Loss Function\": \"Cross Entropy Loss\",\n",
    "    \"IoU_per_class\": iou_per_class,\n",
    "    \"Mean_IoU\": mean_iou,\n",
    "    \"Avg_Dice\": avg_dice,\n",
    "    \"Total_Time\": total_time\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0daa582-19ca-4586-a570-852c89bacb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 32, batch: 1 of 4\n",
      "Input shape: torch.Size([32, 3, 256, 256])\n",
      "Mask shape: torch.Size([32, 256, 256])\n",
      "Inf time:0.8471\n",
      "\n",
      "Batch Size: 32, batch: 2 of 4\n",
      "Inf time:0.8474\n",
      "\n",
      "Batch Size: 32, batch: 3 of 4\n",
      "Inf time:1.3494\n",
      "\n",
      "Batch Size: 5, batch: 4 of 4\n",
      "Inf time:0.1098\n",
      "\n",
      "\n",
      "Dataset Metrics:\n",
      "- Per-class IoU: [0.938  0.8104 0.0988 0.968  0.8339 0.8753 0.3573 0.5182 0.618  0.3382\n",
      " 0.5597 0.2165]\n",
      "- Mean IoU (mIoU): 0.5944\n",
      "- Average Dice: 0.9031\n",
      "- Total Inference Time: 3.1537s\n"
     ]
    }
   ],
   "source": [
    "model = UNET(in_channels=3, out_channels=len(labels_df))\n",
    "state_dict = torch.load(os.path.join(MODEL_PATH, 'best_model_combined.pth'), weights_only=True)\n",
    "missing, unexpected = model.load_state_dict(state_dict)\n",
    "# print(\"Missing keys:\", missing)\n",
    "\n",
    "iou_per_class, mean_iou, avg_dice, total_time = inferences(model,test_dataloader,labels_df)\n",
    "metrics.append({\n",
    "    \"Architecture\": \"UNet\",\n",
    "    \"Loss Function\": \"Dice Loss + Cross Entropy Loss\",\n",
    "    \"IoU_per_class\": iou_per_class,\n",
    "    \"Mean_IoU\": mean_iou,\n",
    "    \"Avg_Dice\": avg_dice,\n",
    "    \"Total_Time\": total_time\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "242e4b97-9a31-4ffb-8572-e9f116b82ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 32, batch: 1 of 4\n",
      "Input shape: torch.Size([32, 3, 256, 256])\n",
      "Mask shape: torch.Size([32, 256, 256])\n",
      "Inf time:0.3424\n",
      "\n",
      "Batch Size: 32, batch: 2 of 4\n",
      "Inf time:0.3365\n",
      "\n",
      "Batch Size: 32, batch: 3 of 4\n",
      "Inf time:0.3434\n",
      "\n",
      "Batch Size: 5, batch: 4 of 4\n",
      "Inf time:0.0510\n",
      "\n",
      "\n",
      "Dataset Metrics:\n",
      "- Per-class IoU: [0.9269 0.7861 0.1391 0.9366 0.8121 0.8435 0.3302 0.     0.6973 0.2852\n",
      " 0.     0.272 ]\n",
      "- Mean IoU (mIoU): 0.5024\n",
      "- Average Dice: 0.8787\n",
      "- Total Inference Time: 1.0733s\n",
      "Batch Size: 32, batch: 1 of 4\n",
      "Input shape: torch.Size([32, 3, 256, 256])\n",
      "Mask shape: torch.Size([32, 256, 256])\n",
      "Inf time:0.3376\n",
      "\n",
      "Batch Size: 32, batch: 2 of 4\n",
      "Inf time:0.3477\n",
      "\n",
      "Batch Size: 32, batch: 3 of 4\n",
      "Inf time:0.3342\n",
      "\n",
      "Batch Size: 5, batch: 4 of 4\n",
      "Inf time:0.0520\n",
      "\n",
      "\n",
      "Dataset Metrics:\n",
      "- Per-class IoU: [0.9269 0.7861 0.1391 0.9366 0.8121 0.8435 0.3302 0.     0.6973 0.2852\n",
      " 0.     0.272 ]\n",
      "- Mean IoU (mIoU): 0.5024\n",
      "- Average Dice: 0.8787\n",
      "- Total Inference Time: 1.0715s\n"
     ]
    }
   ],
   "source": [
    "from architecture import FCN8s\n",
    "import torch\n",
    "\n",
    "model = FCN8s(in_channels=3, out_channels=len(labels_df))\n",
    "state_dict = torch.load(os.path.join(MODEL_PATH_FCN8S, 'best_model_dice.pth'), weights_only=True)\n",
    "missing, unexpected = model.load_state_dict(state_dict)\n",
    "# print(\"Missing keys:\", missing)\n",
    "\n",
    "inferences(model,test_dataloader,labels_df)\n",
    "iou_per_class, mean_iou, avg_dice, total_time = inferences(model,test_dataloader,labels_df)\n",
    "metrics.append({\n",
    "    \"Architecture\": \"FCN8s\",\n",
    "    \"Loss Function\": \"Cross Entropy Loss\",\n",
    "    \"IoU_per_class\": iou_per_class,\n",
    "    \"Mean_IoU\": mean_iou,\n",
    "    \"Avg_Dice\": avg_dice,\n",
    "    \"Total_Time\": total_time\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8044655b-1b2d-4b29-bd58-293d0470d88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 32, batch: 1 of 4\n",
      "Input shape: torch.Size([32, 3, 256, 256])\n",
      "Mask shape: torch.Size([32, 256, 256])\n",
      "Inf time:0.3355\n",
      "\n",
      "Batch Size: 32, batch: 2 of 4\n",
      "Inf time:0.3396\n",
      "\n",
      "Batch Size: 32, batch: 3 of 4\n",
      "Inf time:0.3408\n",
      "\n",
      "Batch Size: 5, batch: 4 of 4\n",
      "Inf time:0.0535\n",
      "\n",
      "\n",
      "Dataset Metrics:\n",
      "- Per-class IoU: [0.8707 0.74   0.     0.7368 0.0332 0.749  0.     0.     0.2407 0.\n",
      " 0.     0.0051]\n",
      "- Mean IoU (mIoU): 0.2813\n",
      "- Average Dice: 0.7703\n",
      "- Total Inference Time: 1.0693s\n"
     ]
    }
   ],
   "source": [
    "from architecture import FCN8s\n",
    "import torch\n",
    "\n",
    "model = FCN8s(in_channels=3, out_channels=len(labels_df))\n",
    "state_dict = torch.load(os.path.join(MODEL_PATH_FCN8S, 'best_model_cross.pth'), weights_only=True)\n",
    "missing, unexpected = model.load_state_dict(state_dict)\n",
    "# print(\"Missing keys:\", missing)\n",
    "\n",
    "iou_per_class, mean_iou, avg_dice, total_time = inferences(model,test_dataloader,labels_df)\n",
    "metrics.append({\n",
    "    \"Architecture\": \"FCN8s\",\n",
    "    \"Loss Function\": \"Cross Entropy Loss\",\n",
    "    \"IoU_per_class\": iou_per_class,\n",
    "    \"Mean_IoU\": mean_iou,\n",
    "    \"Avg_Dice\": avg_dice,\n",
    "    \"Total_Time\": total_time\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b960adbb-0c58-4810-8bc2-3466bd504073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 32, batch: 1 of 4\n",
      "Input shape: torch.Size([32, 3, 256, 256])\n",
      "Mask shape: torch.Size([32, 256, 256])\n",
      "Inf time:0.3340\n",
      "\n",
      "Batch Size: 32, batch: 2 of 4\n",
      "Inf time:0.3383\n",
      "\n",
      "Batch Size: 32, batch: 3 of 4\n",
      "Inf time:0.3411\n",
      "\n",
      "Batch Size: 5, batch: 4 of 4\n",
      "Inf time:0.0510\n",
      "\n",
      "\n",
      "Dataset Metrics:\n",
      "- Per-class IoU: [0.9266 0.8297 0.058  0.9521 0.8267 0.8911 0.3114 0.5265 0.7375 0.2668\n",
      " 0.4567 0.1472]\n",
      "- Mean IoU (mIoU): 0.5775\n",
      "- Average Dice: 0.9005\n",
      "- Total Inference Time: 1.0643s\n"
     ]
    }
   ],
   "source": [
    "from architecture import FCN8s\n",
    "import torch\n",
    "\n",
    "model = FCN8s(in_channels=3, out_channels=len(labels_df))\n",
    "state_dict = torch.load(os.path.join(MODEL_PATH_FCN8S, 'best_model_combined.pth'), weights_only=True)\n",
    "missing, unexpected = model.load_state_dict(state_dict)\n",
    "# print(\"Missing keys:\", missing)\n",
    "\n",
    "iou_per_class, mean_iou, avg_dice, total_time = inferences(model,test_dataloader,labels_df)\n",
    "metrics.append({\n",
    "    \"Architecture\": \"FCN8s\",\n",
    "    \"Loss Function\": \"Dice Loss + Cross Entropy Loss\",\n",
    "    \"IoU_per_class\": iou_per_class,\n",
    "    \"Mean_IoU\": mean_iou,\n",
    "    \"Avg_Dice\": avg_dice,\n",
    "    \"Total_Time\": total_time\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "180ff86b-4847-4ea0-846c-7bf3c287a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics.to_csv(\"inference_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f112a-c3df-4ae4-8200-156c9a593a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNET(in_channels=3, out_channels=len(labels_df))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "state_dict = torch.load(os.path.join(MODEL_PATH, 'best_model_combined.pth'), weights_only=True)\n",
    "missing, unexpected = model.load_state_dict(state_dict)\n",
    "print(\"Missing keys:\", missing)\n",
    "print(\"Unexpected keys:\", unexpected)\n",
    "\n",
    "# Usage with DataLoader\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, masks in test_dataloader:\n",
    "        # Verify shapes\n",
    "        print(\"Input shape:\", images.shape)  # Should be [B,C,H,W]\n",
    "        print(\"Mask shape:\", masks.shape)   # Should be [B,H,W]\n",
    "        \n",
    "        # Run inference\n",
    "        logits, probs, preds = inference(images, model)\n",
    "        iou_score = calculate_iou_scores(masks, preds)\n",
    "        print('masks:')\n",
    "        print(masks)\n",
    "        print()\n",
    "        print('preds: ')\n",
    "        print(preds)\n",
    "        # Verify output shapes\n",
    "        print(\"Logits shape:\", logits.shape)  # Should be [B,C,H,W]\n",
    "        print(\"Preds shape:\", preds.shape)    # Should be [B,H,W]\n",
    "        print(f\"IOU score: {iou_score}\")\n",
    "        print(f\"IOU score mean: {np.mean(iou_score)}\")\n",
    "        dice_score = calculate_dice_coefficients(masks, preds)\n",
    "        print(f\"Dice Coef score: {iou_score}\")\n",
    "        print(f\"Dice Coef score mean: {np.mean(iou_score)}\")\n",
    "        \n",
    "        # Visualize\n",
    "        visualize_results(images, preds, masks, labels_df)\n",
    "        \n",
    "        break  # Only show first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16589d65-0ce6-4eb9-b5d6-28331d57d6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
